"""
Train a Custom YOLOv8 Model — No Cloud, No Roboflow, 100% Local
================================================================
This script trains a YOLOv8 model on YOUR custom dataset — entirely
on your own machine. No internet needed after downloading the base model.

What is Training?
  Training = Teaching YOLO to recognize YOUR specific objects.
  The pre-trained yolov8n.pt already knows 80 common objects (person,
  car, dog, etc.). Training lets you add NEW classes (e.g., "helmet",
  "your_product", "custom_part") or improve detection for specific
  scenarios.

What is Transfer Learning?
  Instead of training from scratch (which needs millions of images),
  we START from the pre-trained yolov8n.pt and fine-tune it on your
  small dataset. This is called "transfer learning" — the model
  already knows edges, shapes, and textures, so it only needs to
  learn your specific objects. Even 50-100 images can work!

Prerequisites:
  1. Annotated images (use the Annotator web tool to label them)
  2. Dataset organized in the correct folder structure
  3. A data.yaml configuration file

Annotation:
  Use our web-based Annotator tool to label images before training:
    uv run python YoloExamples/annotate/app.py
  Then open http://localhost:5000 in your browser.

Dataset Structure:
  YoloExamples/my_dataset/
  ├── data.yaml              ← Dataset config (created by this script)
  ├── train/
  │   ├── images/            ← Training images (80% of your images)
  │   │   ├── img001.jpg
  │   │   └── img002.jpg
  │   └── labels/            ← YOLO labels (from the Annotator)
  │       ├── img001.txt
  │       └── img002.txt
  └── val/
      ├── images/            ← Validation images (20% of your images)
      │   └── img003.jpg
      └── labels/
          └── img003.txt

Usage:
  # Step 1: Organize your dataset (this script helps)
  uv run python YoloExamples/train_custom_model.py --setup \\
      --classes helmet no_helmet

  # Step 2: Put images in my_dataset/train/images/ and
  #          my_dataset/val/images/
  # Then annotate them using the web Annotator:
  #   uv run python YoloExamples/annotate/app.py

  # Step 3: Train!
  uv run python YoloExamples/train_custom_model.py --train

  # Step 4: Test your trained model
  uv run python YoloExamples/train_custom_model.py --predict \\
      --source path/to/test_image.jpg
"""

# ─── Imports ──────────────────────────────────────────────────────────────
from ultralytics import YOLO
import os
import shutil
import random
import argparse
import glob


# ─── Configuration ────────────────────────────────────────────────────────
# Base directory for the custom dataset
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_DIR = os.path.join(SCRIPT_DIR, "my_dataset")
DATA_YAML = os.path.join(DATASET_DIR, "data.yaml")

# Training hyperparameters
# These are good defaults for a small dataset (50-500 images).
# Adjust based on your hardware and dataset size.
EPOCHS = 50           # Number of training rounds
IMAGE_SIZE = 640      # Input image size (pixels)
BATCH_SIZE = 16       # Images per batch (reduce if GPU runs out of memory)
BASE_MODEL = "yolov8n.pt"  # Start from the nano model

# Supported image extensions
IMAGE_EXTENSIONS = (
    ".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"
)


# ─── Setup Dataset Structure ─────────────────────────────────────────────
def setup_dataset(classes):
    """
    Create the dataset folder structure and data.yaml config file.

    This creates:
      my_dataset/
      ├── data.yaml
      ├── train/
      │   ├── images/
      │   └── labels/
      └── val/
          ├── images/
          └── labels/
    """
    print("=" * 60)
    print("  Setting Up Dataset Structure")
    print("=" * 60)

    # Create directories
    dirs = [
        os.path.join(DATASET_DIR, "train", "images"),
        os.path.join(DATASET_DIR, "train", "labels"),
        os.path.join(DATASET_DIR, "val", "images"),
        os.path.join(DATASET_DIR, "val", "labels"),
    ]

    for d in dirs:
        os.makedirs(d, exist_ok=True)
        print(f"  Created: {d}")

    # Create data.yaml
    # This file tells YOLO where to find images and what classes exist.
    yaml_content = f"""# YOLOv8 Dataset Configuration
# Generated by train_custom_model.py
# ──────────────────────────────────────────

# Paths to training and validation images
# (relative to this file's location)
train: train/images
val: val/images

# Number of classes
nc: {len(classes)}

# Class names (order matters — index 0 = first name, etc.)
names: {classes}
"""

    with open(DATA_YAML, "w") as f:
        f.write(yaml_content)
    print(f"\n  Created: {DATA_YAML}")

    print(f"\n  Classes: {classes}")
    print(f"  Number of classes: {len(classes)}")

    print("\n" + "=" * 60)
    print("  Next Steps:")
    print("=" * 60)
    print()
    print("  1. Put your training images (80%) in:")
    print(f"     {dirs[0]}")
    print()
    print("  2. Put your validation images (20%) in:")
    print(f"     {dirs[2]}")
    print()
    print("  3. Annotate images using the web Annotator:")
    print("     uv run python YoloExamples/annotate/app.py")
    print("     Then open http://localhost:5000 and point")
    print("     it to the images/ folders above.")
    print()
    print("  4. Train the model:")
    print("     uv run python YoloExamples/train_custom_model.py"
          " --train")
    print()


# ─── Auto-Split Images ───────────────────────────────────────────────────
def auto_split(source_dir, split_ratio=0.8):
    """
    Automatically split images from a single folder into
    train/ and val/ sets.

    This is useful if you have all images in one folder and
    want to automatically divide them 80/20 for training.

    Args:
        source_dir: Folder containing all images + labels
        split_ratio: Fraction for training (default 0.8 = 80%)
    """
    print("=" * 60)
    print("  Auto-Splitting Images into Train/Val")
    print("=" * 60)

    # Find all images
    images = []
    for ext in IMAGE_EXTENSIONS:
        images.extend(
            glob.glob(os.path.join(source_dir, f"*{ext}"))
        )
    images = sorted(set(images))

    if not images:
        print(f"  No images found in: {source_dir}")
        return

    # Shuffle randomly
    random.shuffle(images)

    # Split
    split_idx = int(len(images) * split_ratio)
    train_images = images[:split_idx]
    val_images = images[split_idx:]

    print(f"  Total images: {len(images)}")
    print(f"  Training:     {len(train_images)} ({split_ratio*100:.0f}%)")
    print(f"  Validation:   {len(val_images)} ({(1-split_ratio)*100:.0f}%)")

    # Copy to train/ and val/
    train_img_dir = os.path.join(DATASET_DIR, "train", "images")
    train_lbl_dir = os.path.join(DATASET_DIR, "train", "labels")
    val_img_dir = os.path.join(DATASET_DIR, "val", "images")
    val_lbl_dir = os.path.join(DATASET_DIR, "val", "labels")

    for d in [train_img_dir, train_lbl_dir, val_img_dir, val_lbl_dir]:
        os.makedirs(d, exist_ok=True)

    def copy_with_label(img_path, dest_img_dir, dest_lbl_dir):
        """Copy an image and its label file to the destination."""
        base = os.path.splitext(os.path.basename(img_path))[0]
        # Copy image
        shutil.copy2(img_path, dest_img_dir)
        # Copy label if it exists
        label_path = os.path.join(
            os.path.dirname(img_path), base + ".txt"
        )
        if os.path.exists(label_path):
            shutil.copy2(label_path, dest_lbl_dir)

    for img in train_images:
        copy_with_label(img, train_img_dir, train_lbl_dir)

    for img in val_images:
        copy_with_label(img, val_img_dir, val_lbl_dir)

    print("\n  Done! Images copied to train/ and val/ folders.")


# ─── Train ────────────────────────────────────────────────────────────────
def train_model(resume=False):
    """
    Train a YOLOv8 model on the custom dataset.

    What happens during training:
      1. YOLO loads the pre-trained weights (yolov8n.pt)
      2. For each epoch (round):
         a. Feed all training images through the model
         b. Compare predictions to your labels (ground truth)
         c. Calculate the "loss" (how wrong the model was)
         d. Adjust the model weights to reduce the loss
         e. Test on validation images to check progress
      3. Save the best model (lowest validation loss)

    Output:
      runs/detect/train/
      ├── weights/
      │   ├── best.pt      ← Best model (use this!)
      │   └── last.pt      ← Last epoch model
      ├── results.png      ← Training curves
      ├── confusion_matrix.png
      └── ...
    """
    print("=" * 60)
    print("  Training YOLOv8 Custom Model")
    print("=" * 60)

    # Check that data.yaml exists
    if not os.path.exists(DATA_YAML):
        print(f"\n  ERROR: {DATA_YAML} not found!")
        print("  Run --setup first to create the dataset structure.")
        return

    # Check that training images exist
    train_img_dir = os.path.join(DATASET_DIR, "train", "images")
    train_images = []
    for ext in IMAGE_EXTENSIONS:
        train_images.extend(
            glob.glob(os.path.join(train_img_dir, f"*{ext}"))
        )
    if not train_images:
        print(f"\n  ERROR: No training images found in {train_img_dir}")
        print("  Add images and annotate them first.")
        return

    print(f"\n  Dataset:    {DATA_YAML}")
    print(f"  Base model: {BASE_MODEL}")
    print(f"  Epochs:     {EPOCHS}")
    print(f"  Image size: {IMAGE_SIZE}")
    print(f"  Batch size: {BATCH_SIZE}")
    print(f"  Training images: {len(train_images)}")
    print()

    if resume:
        # Resume from last checkpoint
        last_pt = os.path.join(
            "runs", "detect", "train", "weights", "last.pt"
        )
        if not os.path.exists(last_pt):
            print(f"  ERROR: {last_pt} not found. Cannot resume.")
            return
        print(f"  Resuming from: {last_pt}")
        model = YOLO(last_pt)
        model.train(resume=True)
    else:
        # Start fresh from pre-trained model
        model = YOLO(BASE_MODEL)
        model.train(
            data=DATA_YAML,
            epochs=EPOCHS,
            imgsz=IMAGE_SIZE,
            batch=BATCH_SIZE,
            name="train",
            project="runs/detect",
            exist_ok=True,
            # ── Data augmentation (helps with small datasets) ──
            # These randomly modify training images so the model
            # sees more variety and generalizes better.
            hsv_h=0.015,    # Hue shift
            hsv_s=0.7,      # Saturation shift
            hsv_v=0.4,      # Brightness shift
            flipud=0.0,     # Vertical flip probability
            fliplr=0.5,     # Horizontal flip probability
            mosaic=1.0,     # Mosaic augmentation (combines 4 images)
            mixup=0.0,      # Mixup augmentation
        )

    print("\n" + "=" * 60)
    print("  Training Complete!")
    print("=" * 60)
    best_pt = os.path.join(
        "runs", "detect", "train", "weights", "best.pt"
    )
    print(f"\n  Best model saved to: {best_pt}")
    print()
    print("  To test your model:")
    print("  uv run python YoloExamples/train_custom_model.py "
          "--predict --source path/to/image.jpg")
    print()
    print("  To run on webcam:")
    print("  uv run python YoloExamples/train_custom_model.py "
          "--predict --source 0")


# ─── Predict ──────────────────────────────────────────────────────────────
def predict(source):
    """
    Run the trained custom model on an image, video, or webcam.

    Args:
        source: Path to image/video, or "0" for webcam
    """
    best_pt = os.path.join(
        "runs", "detect", "train", "weights", "best.pt"
    )

    if not os.path.exists(best_pt):
        print(f"  ERROR: Trained model not found at {best_pt}")
        print("  Train a model first with --train")
        return

    print("=" * 60)
    print("  Running Custom Model Prediction")
    print("=" * 60)
    print(f"\n  Model:  {best_pt}")
    print(f"  Source: {source}")

    model = YOLO(best_pt)

    # If source is "0", convert to int for webcam
    if source == "0":
        source = 0

    results = model(source, show=True, conf=0.5)

    # For images (not webcam), print results
    if isinstance(source, str):
        for r in results:
            print(f"\n  Detected {len(r.boxes)} objects:")
            for box in r.boxes:
                cls_id = int(box.cls[0])
                conf = float(box.conf[0])
                name = r.names[cls_id]
                print(f"    - {name}: {conf:.2f}")


# ─── Validate ─────────────────────────────────────────────────────────────
def validate():
    """
    Validate the trained model on the validation set.
    Shows metrics like mAP, precision, and recall.
    """
    best_pt = os.path.join(
        "runs", "detect", "train", "weights", "best.pt"
    )

    if not os.path.exists(best_pt):
        print(f"  ERROR: Trained model not found at {best_pt}")
        return

    print("=" * 60)
    print("  Validating Custom Model")
    print("=" * 60)

    model = YOLO(best_pt)
    metrics = model.val(data=DATA_YAML)

    print(f"\n  mAP50:    {metrics.box.map50:.4f}")
    print(f"  mAP50-95: {metrics.box.map:.4f}")
    print(f"  Precision: {metrics.box.mp:.4f}")
    print(f"  Recall:    {metrics.box.mr:.4f}")


# ─── Export ───────────────────────────────────────────────────────────────
def export_model(fmt="onnx"):
    """
    Export the trained model to a different format.

    Supported formats:
      onnx     — Universal (CPU, any platform)
      engine   — NVIDIA TensorRT (fast GPU inference)
      tflite   — TensorFlow Lite (mobile, Raspberry Pi)
      coreml   — Apple devices (iOS, macOS)
      openvino — Intel devices
    """
    best_pt = os.path.join(
        "runs", "detect", "train", "weights", "best.pt"
    )

    if not os.path.exists(best_pt):
        print(f"  ERROR: Trained model not found at {best_pt}")
        return

    print(f"  Exporting model to {fmt} format...")
    model = YOLO(best_pt)
    model.export(format=fmt)
    print("  Export complete!")


# ─── Main ─────────────────────────────────────────────────────────────────
def main():
    parser = argparse.ArgumentParser(
        description="Train a custom YOLOv8 model locally"
    )

    # Actions (mutually exclusive)
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--setup", action="store_true",
        help="Create dataset folder structure and data.yaml"
    )
    group.add_argument(
        "--split", type=str, metavar="DIR",
        help="Auto-split images from DIR into train/val"
    )
    group.add_argument(
        "--train", action="store_true",
        help="Train the model on the custom dataset"
    )
    group.add_argument(
        "--resume", action="store_true",
        help="Resume training from last checkpoint"
    )
    group.add_argument(
        "--predict", action="store_true",
        help="Run prediction with the trained model"
    )
    group.add_argument(
        "--validate", action="store_true",
        help="Validate the trained model"
    )
    group.add_argument(
        "--export", type=str, metavar="FORMAT",
        help="Export model (onnx, engine, tflite, coreml, openvino)"
    )

    # Options
    parser.add_argument(
        "--classes", nargs="+", default=["object"],
        help="Class names for --setup (e.g., --classes cat dog)"
    )
    parser.add_argument(
        "--source", type=str, default="0",
        help="Image/video path or '0' for webcam (for --predict)"
    )

    args = parser.parse_args()

    if args.setup:
        setup_dataset(args.classes)
    elif args.split:
        auto_split(args.split)
    elif args.train:
        train_model(resume=False)
    elif args.resume:
        train_model(resume=True)
    elif args.predict:
        predict(args.source)
    elif args.validate:
        validate()
    elif args.export:
        export_model(args.export)


# ─── Entry Point ──────────────────────────────────────────────────────────
if __name__ == "__main__":
    main()
