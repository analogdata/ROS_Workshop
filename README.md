# ROS Workshop â€” ESP8266 LED Control via UDP

Control an LED on an ESP8266 microcontroller using UDP â€” from simple text commands
to AI-powered hand gestures, drowsiness detection, and a multi-node ROS2 keyboard
control system.

---

## Join the Workshop WhatsApp Group - Community Maintained

<p align="center">
  <a href="https://chat.whatsapp.com/GDMHZ3MlXunLEsWuaagXEY?mode=gi_t">
    <img src="docs/Whatsapp QR for Group/IISc-ROS.jpeg" alt="WhatsApp Group QR" width="250"/>
  </a>
</p>

<p align="center">
  <a href="https://chat.whatsapp.com/GDMHZ3MlXunLEsWuaagXEY?mode=gi_t">ðŸ‘‰ Click here to join the WhatsApp Group</a>
</p>

---

## Project Structure

```
ROS_Workshop/
â”œâ”€â”€ p7/                                  # ESP8266 + Python programs
â”‚   â”œâ”€â”€ p7/p7.ino                        # Arduino: ESP8266 UDP LED server
â”‚   â”œâ”€â”€ udp_client.py                    # Simple text-based UDP client
â”‚   â”œâ”€â”€ camera_test.py                   # Basic OpenCV camera test
â”‚   â”œâ”€â”€ finger_udp.py                    # Finger counting â†’ LED control (MediaPipe)
â”‚   â”œâ”€â”€ drowsiness_udp.py               # Drowsiness detection â†’ LED alert (dlib)
â”‚   â”œâ”€â”€ hand_landmarker.task             # [DOWNLOAD] MediaPipe hand model
â”‚   â””â”€â”€ shape_predictor_68_face_landmarks.dat  # [DOWNLOAD] dlib face model
â”‚
â”œâ”€â”€ ros2_my_own_ws/                      # ROS2 Workspace (single-node bridge)
â”‚   â””â”€â”€ src/udp_led_bridge/              # ROS2 package: UDP LED bridge
â”‚       â””â”€â”€ udp_led_bridge/
â”‚           â””â”€â”€ udp_sender_node.py       # ROS2 node: topic â†’ UDP â†’ ESP8266
â”‚
â”œâ”€â”€ ros2_keyboar_led_control/            # ROS2 Workspace (3-node keyboard system)
â”‚   â””â”€â”€ src/keyboard_node/              # ROS2 package: keyboard LED control
â”‚       â””â”€â”€ keyboard_node/
â”‚           â”œâ”€â”€ keyboard_input_node.py   # Node 1: reads keystrokes (a/b/q)
â”‚           â”œâ”€â”€ udp_sender_node.py       # Node 2: sends UDP to ESP8266
â”‚           â””â”€â”€ status_display_node.py   # Node 3: displays LED status
â”‚
â”œâ”€â”€ YoloExamples/                        # YOLO object detection examples
â”‚   â”œâ”€â”€ object_detection.py            # Real-time webcam object detection
â”‚   â”œâ”€â”€ annotate/                      # Web-based annotation tool (Flask)
â”‚   â”‚   â”œâ”€â”€ app.py                   # Flask backend + API routes
â”‚   â”‚   â””â”€â”€ templates/               # Jinja2 + TailwindCSS pages
â”‚   â”œâ”€â”€ annotate_images.py             # CLI annotation tool (OpenCV)
â”‚   â”œâ”€â”€ train_custom_model.py          # Custom YOLO training pipeline
â”‚   â”œâ”€â”€ yolo_training_workflow.ipynb   # Jupyter notebook: full training guide
â”‚   â””â”€â”€ yolov8n.pt                     # [AUTO-DOWNLOAD] YOLOv8 Nano model
â”‚
â”œâ”€â”€ docs/                                # Step-by-step documentation
â”‚   â”œâ”€â”€ 00_installation_and_get_started.md  # Installation guide (Git, ROS2, Arduino, etc.)
â”‚   â”œâ”€â”€ 01_what_is_udp.md               # UDP explained simply
â”‚   â”œâ”€â”€ 02_what_is_ros2.md              # ROS2 concepts for beginners
â”‚   â”œâ”€â”€ 03_project_overview.md          # Project structure & how things connect
â”‚   â”œâ”€â”€ 04_build_and_run.md             # Full build & run instructions
â”‚   â”œâ”€â”€ 05_how_each_program_works.md    # Deep dive into each program
â”‚   â”œâ”€â”€ 06_keyboard_led_control.md      # 3-node keyboard system guide
â”‚   â”œâ”€â”€ 07_yolo_ultralytics.md          # YOLO & Ultralytics deep dive
â”‚   â”œâ”€â”€ 08_annotating_and_training.md   # Annotation, training & public datasets
â”‚   â”œâ”€â”€ Annotator Tool/                 # Annotator tool screenshots
â”‚   â””â”€â”€ Whatsapp QR for Group/          # WhatsApp group QR code image
â”‚
â”œâ”€â”€ pyproject.toml                       # Python dependencies (managed by uv)
â””â”€â”€ README.md                            # You are here!
```

---

## Quick Start

### 1. Flash the ESP8266

Open `p7/p7/p7.ino` in Arduino IDE, select your ESP8266 board, and upload.
Open Serial Monitor (115200 baud) to see the ESP's IP address.

### 2. Install Python Dependencies

```bash
uv sync
```

### 3. Download AI Model Files

These model files are too large for git. Download them into the `p7/` directory:

**MediaPipe Hand Landmarker** (~12 MB) â€” needed by `finger_udp.py`:
```bash
wget -O p7/hand_landmarker.task \
  https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task
```

**dlib Shape Predictor 68** (~99 MB) â€” needed by `drowsiness_udp.py`:
```bash
wget -O p7/shape_predictor_68_face_landmarks.dat.bz2 \
  https://github.com/davisking/dlib-models/raw/master/shape_predictor_68_face_landmarks.dat.bz2
bunzip2 p7/shape_predictor_68_face_landmarks.dat.bz2
```

**YOLOv8 Nano** (~6 MB) â€” needed by `YoloExamples/object_detection.py`:
```bash
cd YoloExamples
uv run python -c "from ultralytics import YOLO; YOLO('yolov8n.pt')"
```
> The model auto-downloads on first run too, but this pre-downloads it.

### 4. Run a Program

```bash
# Test camera
uv run python p7/camera_test.py

# Simple text control (type "on" / "off")
uv run python p7/udp_client.py

# Finger counting (2 fingers = ON, 3 = OFF)
uv run python p7/finger_udp.py

# Drowsiness detection (eyes closed = ON)
uv run python p7/drowsiness_udp.py

# YOLO real-time object detection (press q to quit, s to screenshot)
uv run python YoloExamples/object_detection.py
```

### 5. Run the ROS2 Single-Node Bridge

```bash
cd ros2_my_own_ws
colcon build --packages-select udp_led_bridge
source install/setup.bash

# Terminal 1: Start the node
ros2 run udp_led_bridge udp_sender_node

# Terminal 2: Send commands
ros2 topic pub --once /led_command std_msgs/String "data: 'on'"
ros2 topic pub --once /led_command std_msgs/String "data: 'off'"
```

### 6. Run the ROS2 Keyboard Control (3 Nodes)

```bash
cd ros2_keyboar_led_control
colcon build --packages-select keyboard_node
source install/setup.bash
```

Open **3 terminals** (run `cd ~/ROS_Workshop/ros2_keyboar_led_control && source install/setup.bash` in each):

```bash
# Terminal 1 â€” Status display
ros2 run keyboard_node status_display_node

# Terminal 2 â€” UDP sender
ros2 run keyboard_node udp_sender_node

# Terminal 3 â€” Keyboard input (press a=ON, b=OFF, q=Quit)
ros2 run keyboard_node keyboard_input_node
```

To use a different ESP IP:
```bash
ros2 run keyboard_node udp_sender_node --ros-args -p esp_ip:="192.168.1.50"
```

---

## Programs Overview

| Program | Method | What it does |
|---------|--------|-------------|
| `p7/p7/p7.ino` | Arduino | ESP8266 listens for UDP, controls LED |
| `p7/udp_client.py` | Terminal | Type "on"/"off" to control LED |
| `p7/camera_test.py` | Camera | Test webcam with OpenCV |
| `p7/finger_udp.py` | AI (MediaPipe) | Count fingers â†’ control LED |
| `p7/drowsiness_udp.py` | AI (dlib) | Detect drowsiness â†’ alert LED |
| `udp_sender_node.py` (udp_led_bridge) | ROS2 | Bridge ROS2 topic â†’ UDP â†’ ESP8266 |
| `keyboard_input_node.py` | ROS2 | Read keystrokes (a/b/q), publish commands |
| `udp_sender_node.py` (keyboard_node) | ROS2 | Forward commands via UDP, publish status |
| `status_display_node.py` | ROS2 | Display LED status updates in terminal |
| `YoloExamples/object_detection.py` | AI (YOLO) | Real-time object detection with webcam |
| `YoloExamples/annotate/app.py` | Tool (Flask) | Web-based image annotation (like Roboflow) |
| `YoloExamples/annotate_images.py` | Tool (CLI) | Command-line image annotation (OpenCV) |
| `YoloExamples/train_custom_model.py` | AI (YOLO) | Train/predict/export custom YOLO models |
| `YoloExamples/yolo_training_workflow.ipynb` | Notebook | Interactive Jupyter training guide |

---

## Annotator Tool (Web-Based Image Labeling)

Our browser-based annotation tool for labeling images in YOLO format â€” 100% local, no cloud needed.

```bash
uv run python YoloExamples/annotate/app.py
# Opens at http://localhost:5000
```

**Home Page** â€” Select a folder of images or upload new ones:

![Annotator Home Page](docs/Annotator%20Tool/1.png)

**Folder Browser** â€” Navigate to your images, define classes, and start annotating:

![Annotator Folder Browser](docs/Annotator%20Tool/2.png)

**Annotation Page** â€” Draw bounding boxes, manage classes, track progress, save & export:

![Annotator Annotation Page](docs/Annotator%20Tool/3.png)

Supports **multi-class labeling** â€” draw boxes with different classes on the same image.
Each box becomes a line in the YOLO `.txt` label file. See the
[Annotating & Training docs](docs/08_annotating_and_training.md) for full details.

---

## Network Setup

- **WiFi SSID:** OnePlusRajath
- **ESP8266 Default IP:** 10.160.6.231
- **UDP Port:** 4210
- Both your PC and ESP8266 must be on the **same WiFi network**

---

## Dependencies

**ROS2 Jazzy** is required for the ROS2 workspaces (`ros2_my_own_ws` and `ros2_keyboar_led_control`).

Python packages managed via `pyproject.toml` with [uv](https://docs.astral.sh/uv/):

- **opencv-python** / **opencv-contrib-python** â€” Camera and image processing
- **mediapipe** â€” Google's hand landmark detection
- **dlib** â€” Face landmark detection (68-point model)
- **scipy** â€” Distance calculations for EAR (Eye Aspect Ratio)
- **ultralytics** â€” YOLOv8 object detection
- **flask** â€” Web-based annotation tool
- **jupyterlab** â€” Jupyter notebooks for interactive training
- **matplotlib** â€” Plotting training results
- **requests** â€” HTTP library

---

## Documentation

See the `docs/` folder for beginner-friendly explanations:

0. **[Installation & Getting Started](docs/00_installation_and_get_started.md)** â€” Git, ROS2 Jazzy, Arduino, uv, Docker, Webots, etc.
1. **[What is UDP?](docs/01_what_is_udp.md)** â€” UDP vs TCP, sockets, ports
2. **[What is ROS2?](docs/02_what_is_ros2.md)** â€” Nodes, Topics, Messages, Parameters
3. **[Project Overview](docs/03_project_overview.md)** â€” How everything connects
4. **[Build & Run](docs/04_build_and_run.md)** â€” Step-by-step instructions + troubleshooting
5. **[How Each Program Works](docs/05_how_each_program_works.md)** â€” Deep dive with flowcharts
6. **[Keyboard LED Control](docs/06_keyboard_led_control.md)** â€” 3-node ROS2 system guide
7. **[YOLO & Ultralytics](docs/07_yolo_ultralytics.md)** â€” Object detection deep dive, project ideas, embedded + image processing
8. **[Annotating & Training](docs/08_annotating_and_training.md)** â€” Public datasets, local annotation, training pipeline, complete walkthroughs

---

## License

For educational/workshop use.